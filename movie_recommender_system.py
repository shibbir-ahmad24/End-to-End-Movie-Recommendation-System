# -*- coding: utf-8 -*-
"""movie_recommender_system.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oZsWoSkCOmMXdws92BhhIlucdpPz6smd

# **Content-based Movie Recommendation System**

# **Import The Libraries**
"""

import numpy as np
import pandas as pd

from google.colab import drive
drive.mount('/content/drive/')

"""# **Data Collection**

**Dataset:** https://www.kaggle.com/datasets/tmdb/tmdb-movie-metadata
"""

#loading the dataset to a pandas dataframe
movies = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Movie Recommendation System/tmdb_5000_movies.csv')
credits = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Movie Recommendation System/tmdb_5000_credits.csv')

movies.head(3)

"""# **Data Exploration**"""

movies.shape

credits.head()

"""**Merge the two datasets**"""

movies = movies.merge(credits,on='title')    #Merge the two datasets based on title column

movies = movies[['movie_id','title','overview','genres','keywords','cast','crew']]

movies.head()

"""# **Preprocessing**"""

movies.isnull().sum()

movies.dropna(inplace=True)

movies.isnull().sum()

movies.duplicated().sum()

movies.iloc[0].genres

#we need to convert the 'genres' column as the following -
# [{"id": 28, "name": "Action"}, {"id": 12, "name": "Adventure"}, {"id": 14, "name": "Fantasy"}, {"id": 878, "name": "Science Fiction"}] - ["Action", "Adventure", "Fantasy", "Science Fiction"]

import ast

#ast.literal_eval('[{"id": 28, "name": "Action"}, {"id": 12, "name": "Adventure"}, {"id": 14, "name": "Fantasy"}, {"id": 878, "name": "Science Fiction"}]')

def convert(text):
    L = []
    for i in ast.literal_eval(text):
        L.append(i['name'])
    return L

movies['genres'] = movies['genres'].apply(convert)
movies.head()

movies['keywords'] = movies['keywords'].apply(convert)
movies.head()

def convert3(text):
    L = []
    counter = 0
    for i in ast.literal_eval(text):
        if counter < 3:
            L.append(i['name'])
        counter+=1
    return L

movies['cast'] = movies['cast'].apply(convert3)
movies.head()

#movies['cast'] = movies['cast'].apply(lambda x:x[0:3])

def fetch_director(text):
    L = []
    for i in ast.literal_eval(text):
        if i['job'] == 'Director':
            L.append(i['name'])
    return L

movies['crew'] = movies['crew'].apply(fetch_director)
movies.head()

movies['overview'][0]   #showing string value of overview column

#we use lamba function to convert the string data to a list
movies['overview'] = movies['overview'].apply(lambda x:x.split())
movies.head()

#removing the white space in between the words of the entityes : Sam Worthington -> SamWorthington

movies['genres'] = movies['genres'].apply(lambda x:[i.replace(" ", "")for i in x])
movies['keywords'] = movies['keywords'].apply(lambda x:[i.replace(" ", "")for i in x])
movies['cast'] = movies['cast'].apply(lambda x:[i.replace(" ", "")for i in x])
movies['crew'] = movies['crew'].apply(lambda x:[i.replace(" ", "")for i in x])

movies.head()

#combining the four columns into a single column
movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']

movies.head(2)

#now dropping the four unnecessary columns
new = movies.drop(columns=['overview','genres','keywords','cast','crew'])
new.head()

#convert list to string data in tags column
new['tags'] = new['tags'].apply(lambda x: " ".join(x))

new['tags'][0]

new.head()

import nltk

from nltk.stem.porter import PorterStemmer
ps = PorterStemmer()

def stem(text):
  y = []
  for i in text.split():
      y.append(ps.stem(i))
  return " ".join(y)

new['tags'] = new['tags'].apply(stem)

new.head()

"""# **Vectorization**

We will convert all the texts i.e. movies data to vectors in a 2-dimentional space. so we consider 5000 vectors (as max_features) for 5000 movies data. When user gives a random movie name then the system will show 5 closest movies name / vectors.
"""

from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features=5000,stop_words='english')

vector = cv.fit_transform(new['tags']).toarray()    #toarray() is used as to convert the spars matrix to numpy array

vector.shape

len(cv.get_feature_names_out())

"""# **Calculating Cosine Similarity**

The cosine distance (angle with the origin) exists between the vectors. as this distance is inversely proportional to similarity. we calculate the cosine similarity. if similarity=1, then vectors has the highest similarity, if similarity=0, then vectors has the lowest similarity.
"""

from sklearn.metrics.pairwise import cosine_similarity

#cosine_similarity(vector).shape
similarity = cosine_similarity(vector)

similarity

similarity[0]

similarity.shape

new[new['title'] == 'Avatar']  #finding a specific movie by title in the dataframe

new[new['title'] == 'Batman Begins'].index[0]   #finding the index of a specific movie by title in the dataframe

sorted(list(enumerate(similarity[0])), reverse=True, key= lambda x: x[1])[1:6]  #Getting the similarity value for movie at index 0 to recommend most similar movies

def recommend(movie):
    movie_index = new[new['title'] == movie].index[0]
    distances = similarity[movie_index]
    movies_list = sorted(list(enumerate(distances)), reverse=True, key= lambda x: x[1])[1:6]

    for i in movies_list:
        print(new.iloc[i[0]].title)

recommend('Batman Begins')

import pickle

pickle.dump(new,open('movie_list.pkl','wb'))
pickle.dump(similarity,open('similarity.pkl','wb'))

from google.colab import files

files.download('movie_list.pkl')

files.download('similarity.pkl')

